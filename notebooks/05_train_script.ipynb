{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Script (Notebook Version)\n",
        "\n",
        "This notebook is the notebook version of `scripts/train.py` - train the CLIP model from scratch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install torch torchvision numpy pillow pyyaml tqdm scikit-learn transformers\n",
        "\n",
        "# Mount Google Drive if needed\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import yaml\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Add project to path\n",
        "BASE_DIR = Path('/content/CLIP_model') if Path('/content/CLIP_model').exists() else Path.cwd().parent\n",
        "sys.path.insert(0, str(BASE_DIR))\n",
        "\n",
        "from src.data.coco_dataset import build_coco_dataloader\n",
        "from src.models.clip_model import CLIPModel\n",
        "from src.training.train_clip import get_lr_scheduler, save_checkpoint, train_epoch\n",
        "from src.utils.tokenization import SimpleTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration - adjust these paths as needed\n",
        "CONFIG_PATH = BASE_DIR / \"configs/clip_coco_small.yaml\"\n",
        "RESUME_FROM = None  # Set to checkpoint path if resuming, e.g., \"checkpoints/checkpoint_epoch_5.pt\"\n",
        "\n",
        "# Load config\n",
        "with open(CONFIG_PATH, \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Config: {CONFIG_PATH}\")\n",
        "print(f\"  Resume from: {RESUME_FROM}\")\n",
        "print(f\"  Batch size: {config['training']['batch_size']}\")\n",
        "print(f\"  Learning rate: {config['training']['learning_rate']}\")\n",
        "print(f\"  Epochs: {config['training']['num_epochs']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create directories\n",
        "checkpoint_dir = BASE_DIR / config[\"training\"][\"save_dir\"]\n",
        "checkpoint_dir.mkdir(exist_ok=True, parents=True)\n",
        "print(f\"Checkpoint directory: {checkpoint_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build tokenizer\n",
        "print(\"Building tokenizer vocabulary...\")\n",
        "tokenizer = SimpleTokenizer(\n",
        "    vocab_size=config[\"model\"][\"text\"][\"vocab_size\"], min_freq=2\n",
        ")\n",
        "\n",
        "# Load subset to build vocab\n",
        "temp_loader = build_coco_dataloader(\n",
        "    annotation_file=str(BASE_DIR / config[\"data\"][\"train\"][\"annotation_file\"]),\n",
        "    image_dir=str(BASE_DIR / config[\"data\"][\"train\"][\"image_dir\"]),\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    max_samples=5000,\n",
        ")\n",
        "\n",
        "all_captions = []\n",
        "for batch in tqdm(temp_loader, desc=\"Collecting captions\"):\n",
        "    all_captions.extend(batch[\"caption\"])\n",
        "\n",
        "tokenizer.build_vocab(all_captions)\n",
        "print(f\"Vocabulary size: {len(tokenizer)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "def collate_fn(batch, tokenizer, max_seq_length):\n",
        "    \"\"\"Custom collate function to tokenize captions.\"\"\"\n",
        "    images = torch.stack([item[\"image\"] for item in batch])\n",
        "    captions = [item[\"caption\"] for item in batch]\n",
        "\n",
        "    # Tokenize captions\n",
        "    token_ids = [\n",
        "        tokenizer.encode(cap, max_length=max_seq_length) for cap in captions\n",
        "    ]\n",
        "    token_tensor = torch.tensor(token_ids)\n",
        "\n",
        "    # Create mask (True for padding)\n",
        "    mask = token_tensor == tokenizer.get_pad_token_id()\n",
        "\n",
        "    return {\n",
        "        \"image\": images,\n",
        "        \"text_tokens\": token_tensor,\n",
        "        \"text_mask\": mask,\n",
        "        \"caption\": captions,\n",
        "    }\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = build_coco_dataloader(\n",
        "    annotation_file=str(BASE_DIR / config[\"data\"][\"train\"][\"annotation_file\"]),\n",
        "    image_dir=str(BASE_DIR / config[\"data\"][\"train\"][\"image_dir\"]),\n",
        "    batch_size=config[\"training\"][\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    subset_percentage=config[\"data\"][\"train\"].get(\"subset_percentage\"),\n",
        ").dataset\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config[\"training\"][\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    collate_fn=lambda b: collate_fn(\n",
        "        b, tokenizer, config[\"model\"][\"text\"][\"max_seq_length\"]\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model\n",
        "model = CLIPModel(\n",
        "    vision_config=config[\"model\"][\"vision\"],\n",
        "    text_config=config[\"model\"][\"text\"],\n",
        ").to(device)\n",
        "\n",
        "print(f\"Model created on {device}\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup optimizer and scheduler\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config[\"training\"][\"learning_rate\"],\n",
        "    weight_decay=config[\"training\"][\"weight_decay\"],\n",
        ")\n",
        "\n",
        "num_training_steps = len(train_loader) * config[\"training\"][\"num_epochs\"]\n",
        "scheduler = get_lr_scheduler(\n",
        "    optimizer,\n",
        "    num_warmup_steps=config[\"training\"][\"warmup_steps\"],\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "scaler = (\n",
        "    torch.cuda.amp.GradScaler() if config[\"training\"][\"use_amp\"] else None\n",
        ")\n",
        "\n",
        "print(f\"Optimizer: AdamW\")\n",
        "print(f\"Total training steps: {num_training_steps}\")\n",
        "print(f\"Warmup steps: {config['training']['warmup_steps']}\")\n",
        "print(f\"AMP enabled: {config['training']['use_amp']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resume from checkpoint if provided\n",
        "start_epoch = 0\n",
        "best_loss = float(\"inf\")\n",
        "if RESUME_FROM:\n",
        "    checkpoint_path = BASE_DIR / RESUME_FROM\n",
        "    if checkpoint_path.exists():\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "        scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
        "        start_epoch = checkpoint[\"epoch\"]\n",
        "        best_loss = checkpoint[\"loss\"]\n",
        "        print(f\"Resumed from epoch {start_epoch}, loss: {best_loss:.4f}\")\n",
        "    else:\n",
        "        print(f\"Checkpoint not found: {checkpoint_path}\")\n",
        "else:\n",
        "    print(\"Starting training from scratch\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "for epoch in range(start_epoch, config[\"training\"][\"num_epochs\"]):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{config['training']['num_epochs']}\")\n",
        "\n",
        "    train_loss = train_epoch(\n",
        "        model, train_loader, optimizer, scheduler, scaler, device, config\n",
        "    )\n",
        "    print(f\"Train loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Save checkpoint\n",
        "    if (epoch + 1) % config[\"training\"][\"save_every\"] == 0:\n",
        "        checkpoint_path = save_checkpoint(\n",
        "            model,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            epoch + 1,\n",
        "            train_loss,\n",
        "            checkpoint_dir,\n",
        "            len(tokenizer),\n",
        "        )\n",
        "        print(f\"Checkpoint saved: {checkpoint_path}\")\n",
        "\n",
        "    # Save best model\n",
        "    if train_loss < best_loss:\n",
        "        best_loss = train_loss\n",
        "        best_path = save_checkpoint(\n",
        "            model,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            epoch + 1,\n",
        "            train_loss,\n",
        "            checkpoint_dir,\n",
        "            len(tokenizer),\n",
        "            is_best=True,\n",
        "        )\n",
        "        print(f\"Best model saved: {best_path}\")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
