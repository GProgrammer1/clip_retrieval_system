{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CLIP Model - Getting Started Guide\n",
        "\n",
        "This guide explains how to run the complete pipeline in Google Colab.\n",
        "\n",
        "## üìã Pipeline Overview\n",
        "\n",
        "The complete pipeline consists of these steps:\n",
        "\n",
        "1. **Setup** - Upload project and install dependencies\n",
        "2. **Dataset Exploration** (Optional) - Understand the data\n",
        "3. **Training** - Train the CLIP model\n",
        "4. **Evaluation** - Evaluate model performance\n",
        "5. **Export Embeddings** - Precompute embeddings for faster retrieval\n",
        "6. **Retrieval** - Use the model for image/text search\n",
        "\n",
        "## üöÄ Quick Start\n",
        "\n",
        "**You only need to run notebooks 01, 02, 05, 06, 07, 08 in sequence!**\n",
        "\n",
        "- Notebooks 01-04 are interactive/exploratory\n",
        "- Notebooks 05-08 are the script equivalents (use these for the full pipeline)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup Project in Colab\n",
        "\n",
        "First, you need to get the project code into Colab. Choose one method:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPTION 1: Clone from GitHub (if you've pushed to GitHub)\n",
        "# !git clone https://github.com/yourusername/CLIP_model.git /content/CLIP_model\n",
        "\n",
        "# OPTION 2: Upload project folder to Google Drive, then mount\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# Then copy from Drive to Colab:\n",
        "# !cp -r /content/drive/MyDrive/CLIP_model /content/CLIP_model\n",
        "\n",
        "# OPTION 3: Upload directly to Colab (for small projects)\n",
        "# Use Colab's file upload feature, then unzip if needed\n",
        "\n",
        "# Verify project structure\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "BASE_DIR = Path('/content/CLIP_model')\n",
        "if BASE_DIR.exists():\n",
        "    print(\"‚úÖ Project found!\")\n",
        "    print(f\"Project directory: {BASE_DIR}\")\n",
        "    \n",
        "    # Check important directories\n",
        "    required_dirs = ['src', 'configs', 'notebooks']\n",
        "    for dir_name in required_dirs:\n",
        "        dir_path = BASE_DIR / dir_name\n",
        "        if dir_path.exists():\n",
        "            print(f\"‚úÖ {dir_name}/ exists\")\n",
        "        else:\n",
        "            print(f\"‚ùå {dir_name}/ missing!\")\n",
        "else:\n",
        "    print(\"‚ùå Project not found! Please upload/clone the project first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Prepare COCO Dataset\n",
        "\n",
        "You need the COCO 2017 dataset. The project expects this structure:\n",
        "\n",
        "```\n",
        "CLIP_model/\n",
        "‚îú‚îÄ‚îÄ images/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ annotations_trainval2017/\n",
        "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ annotations/\n",
        "‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ captions_train2017.json\n",
        "‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ captions_val2017.json\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ train2017.1/train2017/  (or train2017/)\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ val2017/\n",
        "```\n",
        "\n",
        "**Options:**\n",
        "1. Download COCO dataset and upload to Colab/Drive\n",
        "2. Use a subset if you have limited storage\n",
        "3. Mount from Google Drive if you have it there\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if dataset is available\n",
        "from pathlib import Path\n",
        "\n",
        "BASE_DIR = Path('/content/CLIP_model')\n",
        "required_files = [\n",
        "    'images/annotations_trainval2017/annotations/captions_train2017.json',\n",
        "    'images/annotations_trainval2017/annotations/captions_val2017.json',\n",
        "]\n",
        "\n",
        "print(\"Checking dataset files...\")\n",
        "all_found = True\n",
        "for file_path in required_files:\n",
        "    full_path = BASE_DIR / file_path\n",
        "    if full_path.exists():\n",
        "        print(f\"‚úÖ {file_path}\")\n",
        "    else:\n",
        "        print(f\"‚ùå {file_path} - NOT FOUND\")\n",
        "        all_found = False\n",
        "\n",
        "if all_found:\n",
        "    print(\"\\n‚úÖ Dataset files found! You're ready to train.\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Some dataset files are missing. Please download COCO dataset.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Run the Pipeline\n",
        "\n",
        "### **Essential Notebooks (Run in this order):**\n",
        "\n",
        "1. **`05_train_script.ipynb`** ‚≠ê **REQUIRED**\n",
        "   - Trains the CLIP model\n",
        "   - Saves checkpoints to `checkpoints/`\n",
        "   - This is the main training step\n",
        "\n",
        "2. **`06_eval_script.ipynb`** ‚≠ê **REQUIRED**\n",
        "   - Evaluates the trained model\n",
        "   - Computes Recall@1, Recall@5, Recall@10\n",
        "   - Saves results to `results/`\n",
        "\n",
        "3. **`07_export_embeddings.ipynb`** ‚≠ê **REQUIRED for retrieval**\n",
        "   - Precomputes embeddings for faster search\n",
        "   - Saves to `embeddings/` directory\n",
        "\n",
        "4. **`08_retrieve_script.ipynb`** ‚≠ê **REQUIRED for using the model**\n",
        "   - Text-to-image search\n",
        "   - Image-to-text search\n",
        "   - Uses precomputed embeddings\n",
        "\n",
        "### **Optional/Exploratory Notebooks:**\n",
        "\n",
        "- **`01_dataset_exploration.ipynb`** - Explore dataset (optional)\n",
        "- **`02_training.ipynb`** - Interactive training (alternative to 05)\n",
        "- **`03_evaluation.ipynb`** - Interactive evaluation (alternative to 06)\n",
        "- **`04_inference_retrieval.ipynb`** - Interactive retrieval (alternative to 08)\n",
        "\n",
        "**Note:** Notebooks 01-04 are more interactive/educational. Notebooks 05-08 are the script equivalents and are what you need for the full pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Important Notes\n",
        "\n",
        "### About Python Files (`src/` directory)\n",
        "\n",
        "**You DON'T run Python files directly!** They are imported by the notebooks.\n",
        "\n",
        "- `src/` contains the actual implementation code\n",
        "- Notebooks import from `src/` (e.g., `from src.models.clip_model import CLIPModel`)\n",
        "- The notebooks are the entry points - they call the code in `src/`\n",
        "\n",
        "### Minimal Pipeline (What you actually need):\n",
        "\n",
        "```\n",
        "1. Upload project to Colab (src/, configs/, notebooks/)\n",
        "2. Upload/download COCO dataset\n",
        "3. Run 05_train_script.ipynb ‚Üí trains model\n",
        "4. Run 06_eval_script.ipynb ‚Üí evaluates model  \n",
        "5. Run 07_export_embeddings.ipynb ‚Üí precomputes embeddings\n",
        "6. Run 08_retrieve_script.ipynb ‚Üí use the model for search\n",
        "```\n",
        "\n",
        "That's it! Everything else is optional.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Configuration\n",
        "\n",
        "Before training, you can adjust the config file:\n",
        "\n",
        "- `configs/clip_coco_tiny.yaml` - Very small (for testing, ~5 min)\n",
        "- `configs/clip_coco_small.yaml` - Small (for development, ~1 hour)\n",
        "- `configs/clip_coco_medium.yaml` - Medium (for production, ~6 hours)\n",
        "- `configs/clip_coco_full.yaml` - Full dataset (~2-3 days)\n",
        "\n",
        "Edit the `CONFIG_PATH` variable in notebook 05 to use a different config.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
